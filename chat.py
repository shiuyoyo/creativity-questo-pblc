import os
import copy
import random
import time
import streamlit as st

import tiktoken
from pydantic import BaseModel, Field

from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage, SystemMessage

import prompts

LANGAUGE_DICT = {
    'E': 'english',
    'C': 'traditional chinese'
}

SCAMPER_DICT = {
    'S' : 'Substitute',
    'C' : 'Combine',
    'A' : 'Adapt',
    'M' : 'Magnify/Modify',
    'P' : 'Put to other uses',
    'E' : 'Eliminate',
    'R' : 'Re-arrange',
}

CHAT_INFO_PLACEHOLDER = {
    'INPUT':{
        'CLS':'',
        'GUIDE':'',
        'EVAL':'',
    },
    'OUTPUT':{
        'CLS':'',
        'GUIDE':'',
        'EVAL':'',
        'NEWQ':'',
    },
    'MISC':{
        'SCAMPER_ELEMENT': '',
        'QUESTION': ''
    }
}

class CLSOutput(BaseModel):
    QType: int = Field(description="Return the types of question student ask as an int 1 or 2 which type 1 is Question for guidance and 2 is Question for activity")

class GUIDEOutput(BaseModel):
    GUID: str = Field(description="Let's think step by step. Analyze the situation e.g. Pros and Cons, importance of different elements/subjects and encourage the student to make their own analysis and decisions.")

class SCAMPEROutput(BaseModel):
    Imprv: str = Field(description="""Let's think step by step. Evaluate the question's strength and weaknesses with suggestion to improvement based the given SCAMPER element and specificity. The question should always be specific. If the question does not contain a target group or more than one target group, remind the student to pick ONLY ONE specific group to focus on. The evaluation and the suggestions should be specific with detailed explainations with elaborations. Under No cicumstances should you mention or quote the word 'SCAMPER', SCAMPER elements or the definition.""")
    NewQ: str = Field(description= "Based on the improvement you suggested, provide a new and better question.")

class LLM:
    def __init__(self):
        self.tknizer = tiktoken.encoding_for_model("gpt-3.5-turbo")  # æ”¹ç”¨3.5çš„tokenizer
        
        # âœ… åŠ å…¥æ¨¡å‹é…ç½®é¸é …
        self.model_config = {
            "cheap": "gpt-3.5-turbo",  # ä¾¿å®œé¸é …
            "free": "gpt-3.5-turbo",   # å…è²»é¡åº¦é¸é …  
            "premium": "gpt-4o-mini"   # é«˜å“è³ªé¸é …
        }
        
        # âœ… æ ¹æ“šç’°å¢ƒè®Šæ•¸æˆ–è¨­å®šé¸æ“‡æ¨¡å‹
        self.model_choice = os.getenv("QST_MODEL_TIER", "cheap")  # é è¨­ä½¿ç”¨ä¾¿å®œé¸é …
        self.selected_model = self.model_config.get(self.model_choice, "gpt-3.5-turbo")
        
        # âœ… æ”¹é€²ï¼šå˜—è©¦å¾ä¸åŒä¾†æºç²å– API Key
        api_key = self._get_api_key()
        
        if not api_key:
            st.error("âš ï¸ OpenAI API Key not found! Please set it in Streamlit Secrets or environment variables.")
            self.api_available = False
            return
            
        # âœ… åŠ å…¥éŒ¯èª¤è™•ç†çš„ LLM åˆå§‹åŒ– - ä½¿ç”¨é¸å®šçš„æ¨¡å‹
        try:
            st.info(f"ğŸ¤– Using model: {self.selected_model} (Cost-saving mode)")
            
            LLM_Classifier = ChatOpenAI(
                model=self.selected_model,
                api_key=api_key,
                max_retries=2,
                request_timeout=30,
                temperature=0.3  # é™ä½temperatureä»¥ç¯€çœæˆæœ¬
            )
            self.LLM_Classifier = LLM_Classifier.with_structured_output(CLSOutput)

            LLM_SCAMPER = ChatOpenAI(
                model=self.selected_model,
                api_key=api_key,
                max_retries=2,
                request_timeout=30,
                temperature=0.7
            )
            self.LLM_SCAMPER = LLM_SCAMPER.with_structured_output(SCAMPEROutput)

            LLM_Guidance = ChatOpenAI(
                model=self.selected_model,
                api_key=api_key,
                max_retries=2,
                request_timeout=30,
                temperature=0.5
            )
            self.LLM_Guidance = LLM_Guidance.with_structured_output(GUIDEOutput)

            self.activity, self.language = None, 'E'
            self.api_available = True
            
        except Exception as e:
            st.error(f"Failed to initialize LLM models: {e}")
            self.api_available = False

    def _get_api_key(self):
        """å˜—è©¦å¾ä¸åŒä¾†æºç²å– API Key"""
        # 1. å˜—è©¦å¾ Streamlit secrets
        if hasattr(st, 'secrets') and 'OPENAI_API_KEY' in st.secrets:
            return st.secrets["OPENAI_API_KEY"]
        
        # 2. å˜—è©¦å¾ç’°å¢ƒè®Šæ•¸
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            return api_key
            
        # 3. å¦‚æœéƒ½æ²’æœ‰ï¼Œè¿”å› None
        return None

    def _retry_api_call(self, api_function, max_retries=3, base_delay=1):
        """å¸¶é‡è©¦æ©Ÿåˆ¶çš„ API èª¿ç”¨"""
        for attempt in range(max_retries):
            try:
                return api_function()
            except Exception as e:
                error_str = str(e).lower()
                error_type = str(type(e).__name__).lower()
                
                # âœ… æª¢æŸ¥æ˜¯å¦ç‚ºé¡åº¦ä¸è¶³éŒ¯èª¤
                if "insufficient_quota" in error_str or "quota" in error_str:
                    st.error("ğŸš« **OpenAI API é¡åº¦ä¸è¶³**")
                    st.error("è«‹æª¢æŸ¥æ‚¨çš„ OpenAI å¸³æˆ¶é¡åº¦ï¼šhttps://platform.openai.com/usage")
                    st.info("ğŸ’¡ **è§£æ±ºæ–¹æ¡ˆ**ï¼š\n1. ç™»å…¥ OpenAI å¹³å°\n2. æŸ¥çœ‹ Billing & Usage\n3. å¢åŠ  API é¡åº¦")
                    return None
                    
                # âœ… æª¢æŸ¥æ˜¯å¦ç‚ºé€Ÿç‡é™åˆ¶éŒ¯èª¤
                elif "rate_limit" in error_str or "ratelimiterror" in error_type:
                    if attempt < max_retries - 1:  # ä¸æ˜¯æœ€å¾Œä¸€æ¬¡å˜—è©¦
                        delay = base_delay * (2 ** attempt)  # æŒ‡æ•¸é€€é¿
                        st.warning(f"â³ Rate limit exceeded. Retrying in {delay} seconds... (Attempt {attempt + 1}/{max_retries})")
                        time.sleep(delay)
                        continue
                    else:
                        st.error("âŒ Rate limit exceeded. Please try again later.")
                        return None
                        
                # âœ… å…¶ä»– API éŒ¯èª¤
                else:
                    st.error(f"âŒ **API Error**: {e}")
                    st.error("è«‹æª¢æŸ¥ OpenAI API Key è¨­å®šæ˜¯å¦æ­£ç¢º")
                    return None
        return None

    def setup_language_and_activity(self, language, activity):
        """âœ… æ•´åˆæ–°ç¨‹å¼ç¢¼çš„æ”¹å–„ï¼šæ›´å¥½çš„æ´»å‹•å…§å®¹è™•ç†"""
        # æª¢æŸ¥æ´»å‹•æ–‡ä»¶
        activities_dir = './activities'
        default_file = os.path.join(activities_dir, 'default.txt')
        
        # å‰µå»º activities ç›®éŒ„ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if not os.path.exists(activities_dir):
            os.makedirs(activities_dir, exist_ok=True)
            
        # å¦‚æœ default.txt ä¸å­˜åœ¨ï¼Œå‰µå»ºå®ƒ
        if not os.path.exists(default_file):
            try:
                with open(default_file, 'w', encoding='utf-8') as f:
                    f.write(prompts.DEFAULT_ACTIVITIY)
            except Exception as e:
                st.warning(f"Could not create default activity file: {e}")
        
        # âœ… æ¡ç”¨æ–°ç¨‹å¼ç¢¼çš„é‚è¼¯ï¼ˆæ‚¨æä¾›çš„æ”¹å–„ç‰ˆæœ¬ï¼‰
        if os.path.isfile(os.path.join(activities_dir, activity)):
            try:
                with open(os.path.join(activities_dir, activity), 'r', encoding='utf-8') as file:
                    self.activity_content = file.read()
            except Exception as e:
                st.warning(f"Could not read activity file: {e}. Using activity as content.")
                self.activity_content = activity
        elif activity == '' or activity is None:
            try:
                with open(default_file, 'r', encoding='utf-8') as file:
                    self.activity_content = file.read()
            except Exception as e:
                st.warning(f"Could not read default activity file: {e}. Using fallback.")
                self.activity_content = prompts.DEFAULT_ACTIVITIY
        else:
            self.activity_content = activity
        
        self.language = language.upper()
        self.activity = activity

    def get_element(self):
        element = random.choice([*'SCAMPER'])
        return element, prompts.EXAMPLES[element]

    def CalculateCost(self, input_messages, output_messages):
        n_inputs, n_outputs = 0, 0
        for input_message in input_messages:
            if input_message:  # ç¢ºä¿è¨Šæ¯ä¸ç‚ºç©º
                try:
                    n_inputs += len(self.tknizer.encode(str(input_message)))
                except Exception:
                    pass
        cost_input = n_inputs/1e7 * 0.15

        for output_message in output_messages:
            if output_message:  # ç¢ºä¿è¨Šæ¯ä¸ç‚ºç©º
                try:
                    n_outputs += len(self.tknizer.encode(str(output_message)))
                except Exception:
                    pass
        cost_output = n_outputs/1e7 * 0.6
        
        return {'cost_input': cost_input, 'cost_output': cost_output, 'ntkn_input': n_inputs, 'ntkn_output': n_outputs}

    def Chat(self, input_question, language, activity):
        """âœ… æ”¹é€²ï¼šåŠ å…¥æˆæœ¬æ§åˆ¶çš„èŠå¤©åŠŸèƒ½"""
        
        # âœ… åŠ å…¥æˆæœ¬æ§åˆ¶æª¢æŸ¥
        if 'api_usage_today' not in st.session_state:
            st.session_state.api_usage_today = 0
        
        # æ¯æ—¥ä½¿ç”¨é™åˆ¶ï¼ˆå¯èª¿æ•´ï¼‰
        DAILY_LIMIT = 50  # æ¯å¤©æœ€å¤š50æ¬¡APIèª¿ç”¨
        
        if st.session_state.api_usage_today >= DAILY_LIMIT:
            return {
                'INPUT': {'CLS': '', 'GUIDE': '', 'EVAL': ''},
                'OUTPUT': {
                    'CLS': '3',
                    'GUIDE': f'ä»Šæ—¥APIä½¿ç”¨å·²é”ä¸Šé™ï¼ˆ{DAILY_LIMIT}æ¬¡ï¼‰ã€‚ç‚ºäº†æ§åˆ¶ç ”ç©¶æˆæœ¬ï¼Œè«‹æ˜å¤©å†ç¹¼çºŒä½¿ç”¨å°Qï¼Œæˆ–å¯ç›´æ¥é€²å…¥ç¬¬4é ä½¿ç”¨å…è²»çš„ChatGPTã€‚',
                    'EVAL': '',
                    'NEWQ': '',
                },
                'MISC': {
                    'SCAMPER_ELEMENT': '',
                    'QUESTION': input_question,
                    'cost_input': 0,
                    'cost_output': 0,
                    'ntkn_input': 0,
                    'ntkn_output': 0
                }
            }
        
        # æª¢æŸ¥ API æ˜¯å¦å¯ç”¨
        if not hasattr(self, 'api_available') or not self.api_available:
            return {
                'INPUT': {'CLS': '', 'GUIDE': '', 'EVAL': ''},
                'OUTPUT': {
                    'CLS': '3',
                    'GUIDE': 'API service is currently unavailable. Please check your OpenAI API configuration in Streamlit Secrets.',
                    'EVAL': '',
                    'NEWQ': '',
                },
                'MISC': {
                    'SCAMPER_ELEMENT': '',
                    'QUESTION': input_question,
                    'cost_input': 0,
                    'cost_output': 0,
                    'ntkn_input': 0,
                    'ntkn_output': 0
                }
            }
        
        if not all([activity == self.activity, language == self.language]):
            self.setup_language_and_activity(language, activity)

        output_dict = copy.deepcopy(CHAT_INFO_PLACEHOLDER)
        output_dict['MISC']['QUESTION'] = input_question

        # âœ… åˆ†é¡å•é¡Œï¼ˆå¸¶é‡è©¦ï¼‰
        cls_message = copy.deepcopy(prompts.CLS_TEMPLATE).replace('{content}', self.activity_content).replace('{question}', input_question)
        
        def classify_question():
            return self.LLM_Classifier.invoke([SystemMessage(content=cls_message)])
            
        QOutput = self._retry_api_call(classify_question)
        
        if QOutput is None:
            # âœ… API èª¿ç”¨å¤±æ•—æ™‚çš„æ™ºèƒ½å‚™ç”¨éŸ¿æ‡‰
            output_dict['OUTPUT']['CLS'] = '2'  # å‡è¨­ç‚ºæ´»å‹•ç›¸é—œå•é¡Œ
            
            # æä¾›åŸºæœ¬çš„ SCAMPER å»ºè­°
            scamper_elements = ['Substitute', 'Combine', 'Adapt', 'Modify', 'Put to other uses', 'Eliminate', 'Rearrange']
            selected_element = random.choice(scamper_elements)
            
            fallback_suggestions = {
                'Substitute': 'ğŸ”„ **æ›¿ä»£æ€è€ƒå»ºè­°**: è€ƒæ…®ç”¨ä¸åŒçš„ææ–™æˆ–åŠŸèƒ½ä¾†æ›¿ä»£åŸæœ‰çš„æ¯›å·¾ç”¨é€”ã€‚ä¾‹å¦‚ï¼šèƒ½å¦ç”¨æ¯›å·¾è£½ä½œå…¶ä»–è³ªåœ°çš„ç‰©å“ï¼Ÿ',
                'Combine': 'ğŸ¤ **çµåˆæ€è€ƒå»ºè­°**: è€ƒæ…®å°‡æ¯›å·¾èˆ‡å…¶ä»–ç‰©å“æˆ–åŠŸèƒ½çµåˆã€‚ä¾‹å¦‚ï¼šæ¯›å·¾èƒ½èˆ‡ä»€éº¼å…¶ä»–é£¯åº—ç”¨å“çµåˆä½¿ç”¨ï¼Ÿ',
                'Adapt': 'ğŸ”§ **é©æ‡‰æ€è€ƒå»ºè­°**: è€ƒæ…®å¦‚ä½•èª¿æ•´æ¯›å·¾çš„å½¢ç‹€ã€å¤§å°æˆ–ç”¨é€”ã€‚ä¾‹å¦‚ï¼šå¦‚ä½•è®“æ¯›å·¾é©åˆä¸åŒå®¢ç¾¤çš„éœ€æ±‚ï¼Ÿ',
                'Modify': 'âš¡ **ä¿®æ”¹æ€è€ƒå»ºè­°**: è€ƒæ…®æ”¾å¤§ã€ç¸®å°æˆ–æ”¹è®Šæ¯›å·¾çš„æŸäº›ç‰¹æ€§ã€‚ä¾‹å¦‚ï¼šå¦‚ä½•è®“æ¯›å·¾è®Šå¾—æ›´æœ‰è¶£æˆ–å¯¦ç”¨ï¼Ÿ',
                'Put to other uses': 'ğŸ¯ **æ–°ç”¨é€”å»ºè­°**: è€ƒæ…®æ¯›å·¾çš„å…¨æ–°ç”¨é€”ã€‚ä¾‹å¦‚ï¼šé™¤äº†æ¸…æ½”ï¼Œæ¯›å·¾é‚„èƒ½ç‚ºå®¢äººæä¾›ä»€éº¼åƒ¹å€¼ï¼Ÿ',
                'Eliminate': 'âŒ **ç°¡åŒ–æ€è€ƒå»ºè­°**: è€ƒæ…®ç§»é™¤æ¯›å·¾çš„æŸäº›å…ƒç´ æˆ–åŠŸèƒ½ã€‚ä¾‹å¦‚ï¼šå“ªäº›éƒ¨åˆ†æ˜¯ä¸å¿…è¦çš„ï¼Ÿ',
                'Rearrange': 'ğŸ”€ **é‡çµ„æ€è€ƒå»ºè­°**: è€ƒæ…®é‡æ–°æ’åˆ—æ¯›å·¾çš„ä½¿ç”¨é †åºæˆ–çµ„ç¹”æ–¹å¼ã€‚ä¾‹å¦‚ï¼šå¦‚ä½•æ”¹è®Šæ¯›å·¾çš„ä½¿ç”¨æµç¨‹ï¼Ÿ'
            }
            
            suggestion = fallback_suggestions.get(selected_element, 'è«‹å˜—è©¦å¾ä¸åŒè§’åº¦æ€è€ƒé€™å€‹å•é¡Œã€‚')
            
            output_dict['OUTPUT']['EVAL'] = f"""âš ï¸ **å°Qç›®å‰é›¢ç·šä¸­** - ä½†é€™è£¡æœ‰ä¸€å€‹å‰µæ„æ€è€ƒå»ºè­°ï¼š

{suggestion}

**æ”¹é€²å»ºè­°**: è«‹è®“æ‚¨çš„å•é¡Œæ›´å…·é«”åŒ–ã€‚ä¾‹å¦‚ï¼š
- å°ˆæ³¨æ–¼ç‰¹å®šçš„å®¢ç¾¤ï¼ˆå•†å‹™æ—…å®¢ã€ç—…æ‚£å®¶å±¬ç­‰ï¼‰
- æ˜ç¢ºèªªæ˜æƒ³è¦çš„ç‰©å“é¡å‹
- è€ƒæ…®å®¢äººçš„å…·é«”éœ€æ±‚å’Œæƒ…å¢ƒ

**å»ºè­°çš„æ”¹å¯«å•é¡Œ**: "å¦‚ä½•å°‡å»¢æ£„æ¯›å·¾è½‰åŒ–ç‚ºå°ä½é™¢ç—…æ‚£å®¶å±¬æœ‰ç”¨çš„comfort itemï¼Ÿ"

ğŸ”§ **æŠ€è¡“æç¤º**: å°Qçš„AIæœå‹™æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œå¯èƒ½æ˜¯APIé…ç½®å•é¡Œã€‚æ‚¨å¯ä»¥ç¹¼çºŒé€²è¡Œæ´»å‹•ï¼Œæˆ–å‰å¾€ç¬¬4é ä½¿ç”¨ChatGPTã€‚"""
            
            output_dict['OUTPUT']['NEWQ'] = f"é‡å°{['å•†å‹™æ—…å®¢', 'æœƒè­°åƒèˆ‡è€…', 'ç—…æ‚£è¦ªå‹', 'è§€å…‰å®¢'][random.randint(0,3)]}ï¼Œå¦‚ä½•é‹ç”¨{selected_element.lower()}çš„æ¦‚å¿µå°‡å»¢æ£„æ¯›å·¾è½‰åŒ–ç‚ºä»¤äººæ„‰æ‚…çš„ç‰©å“ï¼Ÿ"
            output_dict['MISC']['SCAMPER_ELEMENT'] = selected_element
            
            return output_dict
            
        # âœ… å¢åŠ ä½¿ç”¨è¨ˆæ•¸
        st.session_state.api_usage_today += 1
        
        output_dict['INPUT']['CLS'] = cls_message
        output_dict['OUTPUT']['CLS'] = str(QOutput.QType)

        human_message = copy.deepcopy(prompts.USER_TEMPLATE).replace('{question}', input_question)

        # âœ… æŒ‡å°å‹å•é¡Œï¼ˆå¸¶é‡è©¦ï¼‰
        if QOutput.QType == 1:
            guide_message = copy.deepcopy(prompts.GUIDE_TEMPLATE).replace('{content}', self.activity_content).replace('{language}', LANGAUGE_DICT[self.language])
            
            def get_guidance():
                return self.LLM_Guidance.invoke([
                    SystemMessage(content=guide_message),
                    HumanMessage(content=human_message),
                ])
                
            output = self._retry_api_call(get_guidance)
            
            if output:
                output_dict['INPUT']['GUIDE'] = guide_message
                output_dict['OUTPUT']['GUIDE'] = output.GUID
                st.session_state.api_usage_today += 1
            else:
                output_dict['OUTPUT']['GUIDE'] = 'Service temporarily unavailable due to rate limits. Please try again later.'

        # âœ… SCAMPERå‹å•é¡Œï¼ˆå¸¶é‡è©¦ï¼‰
        elif QOutput.QType == 2:
            element, examples = self.get_element()
            activity_message = copy.deepcopy(prompts.SCAMPER_TEMPLATE).replace('{content}', self.activity_content).replace('{element}', element).replace('{examples}', examples).replace('{language}', LANGAUGE_DICT[self.language])
            
            def get_scamper():
                return self.LLM_SCAMPER.invoke([
                    SystemMessage(content=activity_message),
                    HumanMessage(content=human_message),
                ])
                
            output = self._retry_api_call(get_scamper)
            
            if output:
                output_dict['INPUT']['EVAL'] = activity_message
                output_dict['OUTPUT']['EVAL'] = output.Imprv
                output_dict['OUTPUT']['NEWQ'] = output.NewQ
                output_dict['MISC']['SCAMPER_ELEMENT'] = SCAMPER_DICT[element]
                st.session_state.api_usage_today += 1
            else:
                output_dict['OUTPUT']['EVAL'] = 'Service temporarily unavailable due to rate limits. Please try again later.'

        # âœ… æ–°å¢ï¼šéå•é¡Œè™•ç†ï¼ˆä¾†è‡ªåŸå§‹repositoryçš„æ”¹é€²ï¼‰
        elif QOutput.QType == 3:
            if self.language == 'C':
                non_question_message = """ğŸ¤– **å°Qæç¤º**: æ‚¨è¼¸å…¥çš„å…§å®¹ä¼¼ä¹ä¸æ˜¯ä¸€å€‹å•é¡Œã€‚

ç‚ºäº†ç²å¾—æ›´å¥½çš„å”åŠ©ï¼Œè«‹å˜—è©¦ï¼š
ğŸ“ **æå‡ºå…·é«”å•é¡Œ**ï¼šä¾‹å¦‚ã€Œå¦‚ä½•è®“å•†å‹™æ—…å®¢æ›´æ»¿æ„ï¼Ÿã€
ğŸ¯ **èšç„¦ç‰¹å®šç›®æ¨™**ï¼šé¸æ“‡ä¸€å€‹å®¢ç¾¤é€²è¡Œæ·±å…¥æ€è€ƒ
ğŸ’¡ **å°‹æ±‚å»ºè­°**ï¼šè©¢å•æ”¹é€²å‰µæ„çš„æ–¹æ³•

**ç¯„ä¾‹å•é¡Œ**ï¼šã€Œé‡å°ç—…æ‚£å®¶å±¬ï¼Œå»¢æ£„æ¯›å·¾å¯ä»¥å¦‚ä½•è½‰åŒ–ç‚ºå¯¦ç”¨çš„ç‰©å“ï¼Ÿã€"""
            else:
                non_question_message = """ğŸ¤– **Little Q Notice**: Your input doesn't seem to be a question.

For better assistance, please try:
ğŸ“ **Ask specific questions**: e.g., "How to better satisfy business travelers?"
ğŸ¯ **Focus on specific targets**: Choose one customer group for deeper thinking
ğŸ’¡ **Seek advice**: Ask for methods to improve creativity

**Example question**: "For patient families, how can discarded towels be transformed into practical items?" """
            
            output_dict['OUTPUT']['GUIDE'] = non_question_message
        
        # æˆæœ¬è¨ˆç®—
        input_messages = [v for k, v in output_dict['INPUT'].items() if v]
        output_messages = [v for k, v in output_dict['OUTPUT'].items() if v]
        cost_dict = self.CalculateCost(input_messages, output_messages)
        output_dict['MISC'].update(cost_dict)

        # âœ… é¡¯ç¤ºä½¿ç”¨ç‹€æ…‹
        remaining = DAILY_LIMIT - st.session_state.api_usage_today
        st.sidebar.info(f"ğŸ“Š ä»Šæ—¥å‰©é¤˜: {remaining}/{DAILY_LIMIT} æ¬¡")

        return output_dict
